{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "dataS3 = pd.read_csv(\"s3://full-stack-bigdata-datasets/Machine Learning Supervisé/Régression régularisées/news/OnlineNewsPopularity.csv\")\n",
    "\n",
    "data = datasets.fetch_california_housing(data_home=None, download_if_missing=True, return_X_y=False)\n",
    "dataset_houses = pd.DataFrame(columns=data[\"feature_names\"], data=data[\"data\"])\n",
    "\n",
    "informations_data = data.DESCR\n",
    "\n",
    "dataset = pd.read_csv(\"src/titanic.csv\")\n",
    "\n",
    "# Force to display all columns in the notebook\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taille_dataset = dataset.shape\n",
    "\n",
    "nombre_de_ligne = dataset.shape[0] \n",
    "\n",
    "liste_colonne = dataset.columns\n",
    "\n",
    "entete_dataset = dataset[:5]\n",
    "\n",
    "entete_dataset = dataset.head()\n",
    "\n",
    "pied_de_page = dataset[-5:]\n",
    "\n",
    "description = dataset.describe(include='all') # avec valeurs qualitative \n",
    "\n",
    "pourcentage_valeur_manquante = 100*dataset.isnull().sum()/dataset.shape[0]\n",
    "\n",
    "display( dataset )\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulations Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average Price vs. HouseAge\n",
    "mean_price_per_houseage = dataset_houses.groupby('HouseAge')['Price'].mean().reset_index()\n",
    "\n",
    "# supprimer outliers \n",
    "remove_outliers  = dataset.loc[dataset[\"AveRooms\"]<10, :]\n",
    "\n",
    "# Supp colonne 'useless_columns'\n",
    "dataset = dataset.drop(columns= ['useless_columns'])\n",
    "\n",
    "#creation ligne de 1 de la taille du dataset \n",
    "dataset['HasCabin'] = pd.Series([1 for x in range(len(dataset.index))])\n",
    "\n",
    "# condition cellule vide remplace par 0\n",
    "for i in range(len(dataset)):\n",
    "    if pd.isna(dataset['Cabin'][i]):\n",
    "        dataset['HasCabin'][i] = 0\n",
    "\n",
    "# remplace la colonne par du vide \n",
    "dataset['Title'] = np.nan\n",
    "\n",
    "# remplace la colonne vide par Unknow\n",
    "dataset_houses.loc[dataset_houses['City'] == 0, 'City'] = \"Unknown\"\n",
    "\n",
    "# garde condition supperieur à 0 ou sans valeur \n",
    "to_keep = (dataset['Age'] > 0) | (dataset['Age'].isnull())\n",
    "dataset = dataset.loc[to_keep,:]\n",
    "\n",
    "# supression valeur aberante , garde tout ce qui est inferieur à la moyenne + 2 écart type \n",
    "to_keep = dataset['Salary'] < dataset['Salary'].mean() + 2*dataset['Salary'].std()\n",
    "dataset = dataset.loc[to_keep,:]\n",
    "\n",
    "\n",
    "# supprime ou garde la colonne \n",
    "target_name = 'Purchased'\n",
    "Y = dataset.loc[:,target_name] # garde Purchased \n",
    "X = dataset.loc[:,[c for c in dataset.columns if c!=target_name]] # All columns are kept, except the target\n",
    "\n",
    "# transforme en valeur absoluts\n",
    "dataset_valeurs_positive = dataset.apply(lambda x : abs(x))\n",
    "\n",
    "# trie par colonne \n",
    "dataset.sort_values(by=\"coefficients\", ascending=False)\n",
    "\n",
    "# extrait de dataset \n",
    "dataset = dataset.sample(150)\n",
    "\n",
    "# reindexer \n",
    "dataset = dataset.reset_index(drop = True)\n",
    "\n",
    "# creer un tableau de ligne aléatoire d'un autre \n",
    "dataset_dummy= pd.get_dummies(dataset_houses, drop_first=True)\n",
    "\n",
    "# filtre colonnes à grader \n",
    "variables_to_keep = [col for col in dataset.columns if col not in [\"url\", \"weekday_is_sunday\"]]\n",
    "variables_to_keep = dataset.filter(items=['one', 'three'])\n",
    "\n",
    "# concaténation \n",
    "perf_compar = pd.concat([perf_ridge_large_alpha,perf_ridge_small_alpha,perf_lin])\n",
    "\n",
    "# crée Numpy de 0 à 2000 avec pas de 10\n",
    "np.arange(0,2000,10)\n",
    "\n",
    "# remplacement nom de colonnes:\n",
    "data = data.rename(columns= {0: \"Col_1\", 1: \"Col_2\", 2: \"Target\"})\n",
    "\n",
    "# remplace nom de colonnes 'truc_B' par 'truc B':\n",
    "dataset.columns = [col.replace(\" \",\"_\") for col in dataset.columns]\n",
    "\n",
    "data = pd.DataFrame(iris.data, columns = [a.split(\" (\")[0].replace(\" \",\"_\") for a in iris.feature_names])\n",
    "\n",
    "# Nombre de caractère par celule \n",
    "data['Name_length'] = data['Name'].apply(len)\n",
    "\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "data['Has_Cabin'] = data[\"Cabin\"].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "\n",
    "# Cree une collone colinéaire  \n",
    "data['IsAlone'] = 0\n",
    "data.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "# Remove all NULLS in the Embarked column\n",
    "data['Embarked'] = data['Embarked'].fillna('S')\n",
    "data['Embarked'].value_counts()\n",
    "\n",
    "# prend les sufixes 'Bidules.'\n",
    "titanic[\"Title\"] = titanic[\"Name\"].apply(lambda x: re.search(' ([A-Za-z]+)\\.', x).group(1))\n",
    "\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation adresse depuis geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "dataset[\"City\"] = 0\n",
    "for i in range(0, len(dataset)):\n",
    "    geolocator = Nominatim(user_agent=\"yet_another_app_2\")\n",
    "    location = geolocator.reverse(\"{}, {}\".format(dataset.loc[i, \"Latitude\"], dataset.loc[i, \"Longitude\"]), timeout = None)\n",
    "    loc_dict = dict(location.raw)\n",
    "    print(dict(location.raw)[\"address\"])\n",
    "\n",
    "    try:\n",
    "        dataset.loc[i, \"City\"] = loc_dict[\"address\"][\"city\"]\n",
    "    except:\n",
    "        try:\n",
    "            dataset.loc[i, \"City\"] = loc_dict[\"address\"][\"town\"]\n",
    "        except:\n",
    "            try:\n",
    "                dataset.loc[i, \"City\"] = loc_dict[\"address\"][\"village\"]\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
